#+TITLE: Foundations of Convolutional Neural Networks

* Table of Contents :TOC_3_gh:
- [[#convolutional-neural-networks][Convolutional Neural Networks]]
  - [[#computer-vision][Computer Vision]]
  - [[#edge-detection-example][Edge Detection Example]]
  - [[#more-edge-detection][More Edge Detection]]
  - [[#padding][Padding]]
  - [[#strided-convolutions][Strided Convolutions]]
  - [[#convolutions-over-volume][Convolutions Over Volume]]
  - [[#one-layer-of-a-convolutional-network][One Layer of a Convolutional Network]]
  - [[#simple-convolutional-network-example][Simple Convolutional Network Example]]
  - [[#pooling-layers][Pooling Layers]]
  - [[#cnn-example][CNN Example]]
  - [[#why-convolutions][Why Convolutions?]]
- [[#practice-questions][Practice questions]]
- [[#programming-assignments][Programming assignments]]
  - [[#convolutional-model-step-by-step][Convolutional Model: step by step]]
  - [[#convolutional-model-application][Convolutional Model: application]]

* Convolutional Neural Networks
** Computer Vision
[[file:img/screenshot_2017-11-11_11-50-50.png]]

** Edge Detection Example
[[file:img/screenshot_2017-11-11_11-51-52.png]]

[[file:img/screenshot_2017-11-11_11-52-38.png]]

[[file:img/screenshot_2017-11-11_11-53-23.png]]

** More Edge Detection
[[file:img/screenshot_2017-11-11_11-54-21.png]]

[[file:img/screenshot_2017-11-11_11-54-45.png]]

[[file:img/screenshot_2017-11-11_11-56-12.png]]

** Padding
[[file:img/screenshot_2017-11-11_11-57-25.png]]

[[file:img/screenshot_2017-11-11_11-57-58.png]]

** Strided Convolutions
[[file:img/screenshot_2017-11-11_11-58-37.png]]

[[file:img/screenshot_2017-11-11_11-58-52.png]]

[[file:img/screenshot_2017-11-11_11-59-40.png]]

- Actul convolution operation in math requires flipping the filter matrix
- The same operation as convolution without flipping is called cross-correlation in math.
- *But, in machine learning, by the convention, practitioners call the cross-correlation as convolution.*
** Convolutions Over Volume
[[file:img/screenshot_2017-11-11_12-05-22.png]]

** One Layer of a Convolutional Network
[[file:img/screenshot_2017-11-11_12-06-50.png]]

[[file:img/screenshot_2017-11-11_12-07-32.png]]

[[file:img/screenshot_2017-11-11_12-10-14.png]]

** Simple Convolutional Network Example
[[file:img/screenshot_2017-11-11_12-11-41.png]]

** Pooling Layers
[[file:img/screenshot_2017-11-11_12-12-20.png]]

#+BEGIN_QUOTE
But I have to admit, I think the main reason people use max pooling is because it's been found in a lot of experiments to work well.
And the intuition I just described, despite it being often cited, I don't know if anyone fully knows if that's the real underlined reason.
I don't know if anyone knows that that's the real underlying reason that max pooling works well in confidence.
#+END_QUOTE

[[file:img/screenshot_2017-11-11_12-15-47.png]]

[[file:img/screenshot_2017-11-11_12-16-04.png]]

- Max pooling is used in general. Average pooling is rarely used.

[[file:img/screenshot_2017-11-11_12-17-20.png]]

- Generally no padding for pooling layers

** CNN Example
[[file:img/screenshot_2017-11-11_12-18-17.png]]

[[file:img/screenshot_2017-11-11_12-18-31.png]]

** Why Convolutions?
[[file:img/screenshot_2017-11-11_12-18-59.png]]

- Conv layers have relatively small parameters.

[[file:img/screenshot_2017-11-11_12-19-39.png]]

[[file:img/screenshot_2017-11-11_12-19-53.png]]

* Practice questions

* Programming assignments
** Convolutional Model: step by step
[[file:img/screenshot_2017-11-11_22-13-40.png]]

[[file:img/screenshot_2017-11-11_22-17-08.png]]

[[file:img/screenshot_2017-11-11_22-19-28.png]]

[[file:img/screenshot_2017-11-11_22-23-07.png]]

[[file:img/screenshot_2017-11-11_22-27-43.png]]

[[file:img/screenshot_2017-11-11_23-27-30.png]]

[[file:img/screenshot_2017-11-11_23-50-37.png]]

[[file:img/screenshot_2017-11-12_09-55-07.png]]

[[file:img/screenshot_2017-11-12_10-15-19.png]]

[[file:img/screenshot_2017-11-12_10-18-46.png]]

[[file:img/screenshot_2017-11-12_10-19-52.png]]

#+BEGIN_SRC python
  def zero_pad(X, pad):
      # padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)
      return X_pad

  def conv_single_step(a_slice_prev, W, b):
      # a scalar value, result of convolving the sliding window (W, b) on a slice x of the input data
      return Z

  def conv_forward(A_prev, W, b, hparameters):
      return Z, cache

  def pool_forward(A_prev, hparameters, mode = "max"):
      return A, cache

  def conv_backward(dZ, cache):
      return dA_prev, dW, db

  def create_mask_from_window(x):
      # Array of the same shape as window, contains a True at the position corresponding to the max entry of x.
      return mask

  def distribute_value(dz, shape):
      # Array of size (n_H, n_W) for which we distributed the value of dz
      return a

  def pool_backward(dA, cache, mode = "max"):
      return dA_prev
#+END_SRC

** Convolutional Model: application
[[file:img/screenshot_2017-11-12_04-01-23.png]]

[[file:img/screenshot_2017-11-12_04-12-44.png]]

[[file:img/screenshot_2017-11-12_04-12-31.png]]

[[file:img/screenshot_2017-11-12_04-13-05.png]]

[[file:img/screenshot_2017-11-12_04-28-26.png]]

[[file:img/screenshot_2017-11-12_04-31-32.png]]

#+BEGIN_SRC python
  def create_placeholders(n_H0, n_W0, n_C0, n_y):
      return X, Y

  def initialize_parameters():
      parameters = {"W1": W1,
                    "W2": W2}
      return parameters

  def forward_propagation(X, parameters):
      return Z3

  def compute_cost(Z3, Y):
      return cost
#+END_SRC
