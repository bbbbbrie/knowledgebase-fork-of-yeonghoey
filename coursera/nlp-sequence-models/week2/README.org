#+TITLE: Natural Language Processing & Word Embeddings

* Table of Contents :TOC_3_gh:
- [[#introduction-to-word-embeddings][Introduction to Word Embeddings]]
  - [[#word-representation][Word Representation]]
  - [[#using-word-embeddings][Using word embeddings]]
  - [[#properties-of-word-embeddings][Properties of word embeddings]]
  - [[#embedding-matrix][Embedding matrix]]
- [[#learning-word-embeddings-word2vec--glove][Learning Word Embeddings: Word2vec & GloVe]]
  - [[#learning-word-embeddings][Learning word embeddings]]
  - [[#word2vec][Word2Vec]]
  - [[#negative-sampling][Negative Sampling]]
  - [[#glove-word-vectors][GloVe word vectors]]
- [[#applications-using-word-embeddings][Applications using Word Embeddings]]
  - [[#sentiment-classification][Sentiment Classification]]
  - [[#debiasing-word-embeddings][Debiasing word embeddings]]
- [[#practice-questions][Practice questions]]
  - [[#quiz-natural-language-porcessing--word-embeddings][Quiz: Natural Language Porcessing & Word Embeddings]]
- [[#programming-assignments][Programming assignments]]
  - [[#operations-on-word-vectors---debiasing][Operations on word vectors - Debiasing]]
  - [[#emojify][Emojify]]

* Introduction to Word Embeddings
** Word Representation
[[file:img/screenshot_2018-02-11_22-32-17.png]]

[[file:img/screenshot_2018-02-11_22-37-17.png]]

[[file:img/screenshot_2018-02-11_22-40-11.png]]

** Using word embeddings
[[file:img/screenshot_2018-02-11_22-44-37.png]]

[[file:img/screenshot_2018-02-11_22-49-04.png]]

[[file:img/screenshot_2018-02-11_22-51-45.png]]
- The word embeddings of nlp funciton in a similar way as face encoding of face recognition.
- While word embeddings have a fixed number of inputs(vocabulary),
  face encoding differs in that it can have an infinite number of inputs(face images).

** Properties of word embeddings
[[file:img/screenshot_2018-02-11_23-11-50.png]]

[[file:img/screenshot_2018-02-11_23-16-24.png]]

[[file:img/screenshot_2018-02-11_23-19-10.png]]

** Embedding matrix
[[file:img/screenshot_2018-02-11_23-25-37.png]]

* Learning Word Embeddings: Word2vec & GloVe
** Learning word embeddings
[[file:img/screenshot_2018-02-12_10-33-46.png]]

[[file:img/screenshot_2018-02-12_10-37-12.png]]

** Word2Vec
[[file:img/screenshot_2018-02-12_10-40-40.png]]

[[file:img/screenshot_2018-02-12_10-45-31.png]]

- ~theta t~ is the parameter associated with the output ~t~.

[[file:img/screenshot_2018-02-12_10-50-30.png]]

- If you sample the context uniformly at radom, words like ~the~, ~of~, ~a~ , ~and~ will dominate the context.
- So there is some other heuristic method to sample the context.

** Negative Sampling
[[file:img/screenshot_2018-02-12_11-06-52.png]]

[[file:img/screenshot_2018-02-12_11-13-43.png]]

- Each target word(10k) has their binary classification model.
- Each model takes word embeddings as inputs, in previous examples, 300 features.
- Each model predicts probability of the word in charge.

[[file:img/screenshot_2018-02-12_15-38-08.png]]

- ~f(wi)^3/4~ is heuristic value, which is in between ~frequency distribution~ and ~uniform distribution~.

** GloVe word vectors
[[file:img/screenshot_2018-02-12_15-44-28.png]]

[[file:img/screenshot_2018-02-12_15-53-17.png]]

[[file:img/screenshot_2018-02-12_15-56-58.png]]

- Each feature can't be completely orgthogonal.
- But it still makes sense when it comes to word similarity.

* Applications using Word Embeddings
** Sentiment Classification
[[file:img/screenshot_2018-02-12_16-04-45.png]]

[[file:img/screenshot_2018-02-12_16-08-03.png]]

[[file:img/screenshot_2018-02-12_16-10-09.png]]

** Debiasing word embeddings
- the term ~bias~ in this lecture is NOT the ~bias~ as a parameter, but the bias in learned feature.

[[file:img/screenshot_2018-02-12_16-16-08.png]]

[[file:img/screenshot_2018-02-12_16-23-06.png]]

* Practice questions
** Quiz: Natural Language Porcessing & Word Embeddings

[[file:img/screenshot_2018-02-12_16-26-15.png]]

[[file:img/screenshot_2018-02-12_16-42-34.png]]

[[file:img/screenshot_2018-02-12_16-43-09.png]]

* Programming assignments
** Operations on word vectors - Debiasing
** Emojify
