<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-120656861-1"></script>
  <script>
   window.dataLayer = window.dataLayer || [];
   function gtag(){dataLayer.push(arguments);}
   gtag('js', new Date());
   gtag('config', 'UA-120656861-1');
  </script>

  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />


  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#00aba9">
  <meta name="theme-color" content="#ffffff">

  <title>Object Detection</title>

  <style type="text/css">
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>

  <style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>

  <link rel="stylesheet" href="/_css/content.css" />


  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->

  <link href="https://fonts.googleapis.com/css?family=Roboto|Roboto+Condensed|Roboto+Mono" rel="stylesheet">
</head>
<body>
<nav class="menu">
  <ol class="breadcrumb">
    <li><a href="/" >Home</a></li>
    <li><a href="/coursera/" >coursera</a></li>
    <li><a href="/coursera/deeplearning-ai/" >deeplearning-ai</a></li>
    <li><a href="/coursera/deeplearning-ai/convolutional-neural-networks/" >convolutional-neural-networks</a></li>
    <li>week3</li>
  </ol>
</nav>

<article>
<header>
<h1 class="title">Object Detection</h1>
</header>

<nav class="toc">
<h2>Table of Contents</h2>
<ul>
<li><a href="#detection-algorithms">Detection algorithms</a><ul>
<li><a href="#object-localization">Object Localization</a></li>
<li><a href="#landmark-detection">Landmark Detection</a></li>
<li><a href="#object-detection-1">Object Detection</a></li>
<li><a href="#convolutional-implementation-of-sliding-windows">Convolutional Implementation of Sliding Windows</a></li>
<li><a href="#bounding-box-predictions">Bounding Box Predictions</a></li>
<li><a href="#intersection-over-union">Intersection Over Union</a></li>
<li><a href="#non-max-suppression">Non-max Suppression</a></li>
<li><a href="#anchor-boxes">Anchor Boxes</a></li>
<li><a href="#yolo-algorithm">YOLO Algorithm</a></li>
<li><a href="#optional-region-proposals">(Optional) Region Proposals</a></li>
</ul></li>
<li><a href="#programming-assignments">Programming assignments</a><ul>
<li><a href="#car-detection-with-yolov2">Car detection with YOLOv2</a></li>
</ul></li>
</ul>
</nav>

<h1 id="detection-algorithms">Detection algorithms</h1>
<h2 id="object-localization">Object Localization</h2>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-24_23-33-19.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-24_23-33-47.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-24_23-35-51.png" /></p>
<h2 id="landmark-detection">Landmark Detection</h2>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-24_23-37-23.png" /></p>
<h2 id="object-detection-1">Object Detection</h2>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-24_23-59-56.png" /></p>
<h2 id="convolutional-implementation-of-sliding-windows">Convolutional Implementation of Sliding Windows</h2>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_00-23-41.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-00-09.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-00-38.png" /></p>
<h2 id="bounding-box-predictions">Bounding Box Predictions</h2>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-01-39.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-01-57.png" /></p>
<h2 id="intersection-over-union">Intersection Over Union</h2>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-02-34.png" /></p>
<h2 id="non-max-suppression">Non-max Suppression</h2>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-03-03.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-03-29.png" /></p>
<h2 id="anchor-boxes">Anchor Boxes</h2>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-04-02.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-04-20.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-04-49.png" /></p>
<ul>
<li>Anchor boxes are not only for dealing with multiple mid points in one grid.</li>
<li>Anchor boxes specialize each detecting object.</li>
</ul>
<h2 id="yolo-algorithm">YOLO Algorithm</h2>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-08-01.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-08-15.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-08-37.png" /></p>
<h2 id="optional-region-proposals">(Optional) Region Proposals</h2>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-09-08.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-09-27.png" /></p>
<h1 id="programming-assignments">Programming assignments</h1>
<h2 id="car-detection-with-yolov2">Car detection with YOLOv2</h2>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-23-48.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-25-44.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-27-20.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-28-40.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-29-42.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_10-56-43.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_11-05-09.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_11-14-47.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_11-20-43.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_11-22-23.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_11-22-57.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_11-23-41.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_11-33-18.png" /></p>
<p><img src="https://media.yeonghoey.com/coursera/deeplearning-ai/convolutional-neural-networks/week3/_img/screenshot_2017-11-25_11-33-38.png" /></p>
<ul>
<li><a href="https://keras.io/backend/#argmax" class="uri">https://keras.io/backend/#argmax</a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/boolean_mask" class="uri">https://www.tensorflow.org/api_docs/python/tf/boolean_mask</a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/image/non_max_suppression" class="uri">https://www.tensorflow.org/api_docs/python/tf/image/non_max_suppression</a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/gather" class="uri">https://www.tensorflow.org/api_docs/python/tf/gather</a></li>
</ul>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">def</span> yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold <span class="op">=</span> <span class="fl">.6</span>):</a>
<a class="sourceLine" id="cb1-2" data-line-number="2">    <span class="co">&quot;&quot;&quot;Filters YOLO boxes by thresholding on object and class confidence.</span></a>
<a class="sourceLine" id="cb1-3" data-line-number="3"></a>
<a class="sourceLine" id="cb1-4" data-line-number="4"><span class="co">    Arguments:</span></a>
<a class="sourceLine" id="cb1-5" data-line-number="5"><span class="co">    box_confidence -- tensor of shape (19, 19, 5, 1)</span></a>
<a class="sourceLine" id="cb1-6" data-line-number="6"><span class="co">    boxes -- tensor of shape (19, 19, 5, 4)</span></a>
<a class="sourceLine" id="cb1-7" data-line-number="7"><span class="co">    box_class_probs -- tensor of shape (19, 19, 5, 80)</span></a>
<a class="sourceLine" id="cb1-8" data-line-number="8"><span class="co">    threshold -- real value, if [ highest class probability score &lt; threshold], then get rid of the corresponding box</span></a>
<a class="sourceLine" id="cb1-9" data-line-number="9"></a>
<a class="sourceLine" id="cb1-10" data-line-number="10"><span class="co">    Returns:</span></a>
<a class="sourceLine" id="cb1-11" data-line-number="11"><span class="co">    scores -- tensor of shape (None,), containing the class probability score for selected boxes</span></a>
<a class="sourceLine" id="cb1-12" data-line-number="12"><span class="co">    boxes -- tensor of shape (None, 4), containing (b_x, b_y, b_h, b_w) coordinates of selected boxes</span></a>
<a class="sourceLine" id="cb1-13" data-line-number="13"><span class="co">    classes -- tensor of shape (None,), containing the index of the class detected by the selected boxes</span></a>
<a class="sourceLine" id="cb1-14" data-line-number="14"></a>
<a class="sourceLine" id="cb1-15" data-line-number="15"><span class="co">    Note: &quot;None&quot; is here because you don&#39;t know the exact number of selected boxes, as it depends on the threshold.</span></a>
<a class="sourceLine" id="cb1-16" data-line-number="16"><span class="co">    For example, the actual output size of scores would be (10,) if there are 10 boxes.</span></a>
<a class="sourceLine" id="cb1-17" data-line-number="17"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb1-18" data-line-number="18">    <span class="cf">return</span> scores, boxes, classes</a>
<a class="sourceLine" id="cb1-19" data-line-number="19"></a>
<a class="sourceLine" id="cb1-20" data-line-number="20"><span class="kw">def</span> yolo_non_max_suppression(scores, boxes, classes, max_boxes <span class="op">=</span> <span class="dv">10</span>, iou_threshold <span class="op">=</span> <span class="fl">0.5</span>):</a>
<a class="sourceLine" id="cb1-21" data-line-number="21">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb1-22" data-line-number="22"><span class="co">    Applies Non-max suppression (NMS) to set of boxes</span></a>
<a class="sourceLine" id="cb1-23" data-line-number="23"></a>
<a class="sourceLine" id="cb1-24" data-line-number="24"><span class="co">    Arguments:</span></a>
<a class="sourceLine" id="cb1-25" data-line-number="25"><span class="co">    scores -- tensor of shape (None,), output of yolo_filter_boxes()</span></a>
<a class="sourceLine" id="cb1-26" data-line-number="26"><span class="co">    boxes -- tensor of shape (None, 4), output of yolo_filter_boxes() that have been scaled to the image size (see later)</span></a>
<a class="sourceLine" id="cb1-27" data-line-number="27"><span class="co">    classes -- tensor of shape (None,), output of yolo_filter_boxes()</span></a>
<a class="sourceLine" id="cb1-28" data-line-number="28"><span class="co">    max_boxes -- integer, maximum number of predicted boxes you&#39;d like</span></a>
<a class="sourceLine" id="cb1-29" data-line-number="29"><span class="co">    iou_threshold -- real value, &quot;intersection over union&quot; threshold used for NMS filtering</span></a>
<a class="sourceLine" id="cb1-30" data-line-number="30"></a>
<a class="sourceLine" id="cb1-31" data-line-number="31"><span class="co">    Returns:</span></a>
<a class="sourceLine" id="cb1-32" data-line-number="32"><span class="co">    scores -- tensor of shape (, None), predicted score for each box</span></a>
<a class="sourceLine" id="cb1-33" data-line-number="33"><span class="co">    boxes -- tensor of shape (4, None), predicted box coordinates</span></a>
<a class="sourceLine" id="cb1-34" data-line-number="34"><span class="co">    classes -- tensor of shape (, None), predicted class for each box</span></a>
<a class="sourceLine" id="cb1-35" data-line-number="35"></a>
<a class="sourceLine" id="cb1-36" data-line-number="36"><span class="co">    Note: The &quot;None&quot; dimension of the output tensors has obviously to be less than max_boxes. Note also that this</span></a>
<a class="sourceLine" id="cb1-37" data-line-number="37"><span class="co">    function will transpose the shapes of scores, boxes, classes. This is made for convenience.</span></a>
<a class="sourceLine" id="cb1-38" data-line-number="38"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb1-39" data-line-number="39">    <span class="cf">return</span> scores, boxes, classes</a>
<a class="sourceLine" id="cb1-40" data-line-number="40"></a>
<a class="sourceLine" id="cb1-41" data-line-number="41"><span class="kw">def</span> yolo_eval(yolo_outputs, image_shape <span class="op">=</span> (<span class="fl">720.</span>, <span class="fl">1280.</span>), max_boxes<span class="op">=</span><span class="dv">10</span>, score_threshold<span class="op">=</span>.<span class="dv">6</span>, iou_threshold<span class="op">=</span>.<span class="dv">5</span>):</a>
<a class="sourceLine" id="cb1-42" data-line-number="42">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb1-43" data-line-number="43"><span class="co">    Converts the output of YOLO encoding (a lot of boxes) to your predicted boxes along with their scores, box coordinates and classes.</span></a>
<a class="sourceLine" id="cb1-44" data-line-number="44"></a>
<a class="sourceLine" id="cb1-45" data-line-number="45"><span class="co">    Arguments:</span></a>
<a class="sourceLine" id="cb1-46" data-line-number="46"><span class="co">    yolo_outputs -- output of the encoding model (for image_shape of (608, 608, 3)), contains 4 tensors:</span></a>
<a class="sourceLine" id="cb1-47" data-line-number="47"><span class="co">                    box_confidence: tensor of shape (None, 19, 19, 5, 1)</span></a>
<a class="sourceLine" id="cb1-48" data-line-number="48"><span class="co">                    box_xy: tensor of shape (None, 19, 19, 5, 2)</span></a>
<a class="sourceLine" id="cb1-49" data-line-number="49"><span class="co">                    box_wh: tensor of shape (None, 19, 19, 5, 2)</span></a>
<a class="sourceLine" id="cb1-50" data-line-number="50"><span class="co">                    box_class_probs: tensor of shape (None, 19, 19, 5, 80)</span></a>
<a class="sourceLine" id="cb1-51" data-line-number="51"><span class="co">    image_shape -- tensor of shape (2,) containing the input shape, in this notebook we use (608., 608.) (has to be float32 dtype)</span></a>
<a class="sourceLine" id="cb1-52" data-line-number="52"><span class="co">    max_boxes -- integer, maximum number of predicted boxes you&#39;d like</span></a>
<a class="sourceLine" id="cb1-53" data-line-number="53"><span class="co">    score_threshold -- real value, if [ highest class probability score &lt; threshold], then get rid of the corresponding box</span></a>
<a class="sourceLine" id="cb1-54" data-line-number="54"><span class="co">    iou_threshold -- real value, &quot;intersection over union&quot; threshold used for NMS filtering</span></a>
<a class="sourceLine" id="cb1-55" data-line-number="55"></a>
<a class="sourceLine" id="cb1-56" data-line-number="56"><span class="co">    Returns:</span></a>
<a class="sourceLine" id="cb1-57" data-line-number="57"><span class="co">    scores -- tensor of shape (None, ), predicted score for each box</span></a>
<a class="sourceLine" id="cb1-58" data-line-number="58"><span class="co">    boxes -- tensor of shape (None, 4), predicted box coordinates</span></a>
<a class="sourceLine" id="cb1-59" data-line-number="59"><span class="co">    classes -- tensor of shape (None,), predicted class for each box</span></a>
<a class="sourceLine" id="cb1-60" data-line-number="60"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb1-61" data-line-number="61">    <span class="cf">return</span> scores, boxes, classes</a></code></pre></div>
</article>

</body>
</html>
