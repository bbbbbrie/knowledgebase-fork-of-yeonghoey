#+TITLE: Hyperparameter tuning, Batch Normalization and Programming Frameworks

* Table of Contents :TOC_3_gh:
- [[#hyperparameter-tuning][Hyperparameter tuning]]
  - [[#tuning-process][Tuning process]]
  - [[#using-an-appropriate-scale-to-pick-hyperparameters][Using an appropriate scale to pick hyperparameters]]
  - [[#hyperparameters-tuning-in-practice-pandas-vs-caviar][Hyperparameters tuning in practice: Pandas vs. Caviar]]

* Hyperparameter tuning
** Tuning process
[[file:img/screenshot_2017-10-24_07-04-16.png]]

- Order of importance :: ~red~ > ~orange~ > ~purple~
- Hyperparameters for Adam :: Use default values for most cases

[[file:img/screenshot_2017-10-24_07-08-48.png]]

- *Prefer random values to grid values*
- It's hard to know which parameters are more important.
- Using grid, there would be lots of meaningless tests.
- These points go deep when there are more dimensions.

[[file:img/screenshot_2017-10-24_07-13-47.png]]

- At first, pick random values in wide range.
- When you find some points work better, narrow the random ranges.

** Using an appropriate scale to pick hyperparameters
[[file:img/screenshot_2017-10-24_07-17-49.png]]

- It's not always effective to pick hyperparameters by sampling uniformly at random.

[[file:img/screenshot_2017-10-24_07-22-27.png]]

[[file:img/screenshot_2017-10-24_07-26-26.png]]

** Hyperparameters tuning in practice: Pandas vs. Caviar
[[file:img/screenshot_2017-10-24_07-47-41.png]]

[[file:img/screenshot_2017-10-24_07-52-27.png]]

- Depends on available computation resources.
